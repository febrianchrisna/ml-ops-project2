{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\n",
    "from modules.pipeline import init_local_pipeline\n",
    "from modules.components import init_components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_NAME = \"chrisnaa-pipeline\"\n",
    "\n",
    "# Pipeline inputs root\n",
    "DATA_ROOT = \"data\"\n",
    "TRANSFORM_MODULE_FILE = \"modules/transform.py\"\n",
    "TUNER_MODULE_FILE = \"modules/tuner.py\"\n",
    "TRAINER_MODULE_FILE = \"modules/trainer.py\"\n",
    "\n",
    "# Pipeline outputs root\n",
    "OUTPUT_BASE = \"outputs\"\n",
    "serving_model_dir = os.path.join(OUTPUT_BASE, \"serving_model\")\n",
    "pipeline_root = os.path.join(OUTPUT_BASE, PIPELINE_NAME)\n",
    "metadata_path = os.path.join(pipeline_root, \"metadata.sqlite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 17s]\n",
      "binary_accuracy: 0.9979593753814697\n",
      "\n",
      "Best binary_accuracy So Far: 0.9979593753814697\n",
      "Total elapsed time: 00h 00m 46s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in outputs\\chrisnaa-pipeline\\Tuner\\.system\\executor_execution\\93\\.temp\\93\\kt_randomsearch\n",
      "Showing 10 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x000002790421E2E0>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_hidden_layers: 3\n",
      "dense_unit: 240\n",
      "dropout_rate: 0.5\n",
      "learning_rate: 0.001\n",
      "Score: 0.9979593753814697\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_hidden_layers: 3\n",
      "dense_unit: 176\n",
      "dropout_rate: 0.4\n",
      "learning_rate: 0.01\n",
      "Score: 0.9968875050544739\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_hidden_layers: 1\n",
      "dense_unit: 208\n",
      "dropout_rate: 0.7000000000000001\n",
      "learning_rate: 0.0001\n",
      "Score: 0.9784530997276306\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_hidden_layers: 2\n",
      "dense_unit: 16\n",
      "dropout_rate: 0.7000000000000001\n",
      "learning_rate: 0.001\n",
      "Score: 0.9111031293869019\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_hidden_layers: 1\n",
      "dense_unit: 16\n",
      "dropout_rate: 0.30000000000000004\n",
      "learning_rate: 0.0001\n",
      "Score: 0.9053312540054321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Sex_xf (InputLayer)            [(None, 3)]          0           []                               \n",
      "                                                                                                  \n",
      " Red_pixel_xf (InputLayer)      [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Green_pixel_xf (InputLayer)    [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Blue_pixel_xf (InputLayer)     [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Hb_xf (InputLayer)             [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 7)            0           ['Sex_xf[0][0]',                 \n",
      "                                                                  'Red_pixel_xf[0][0]',           \n",
      "                                                                  'Green_pixel_xf[0][0]',         \n",
      "                                                                  'Blue_pixel_xf[0][0]',          \n",
      "                                                                  'Hb_xf[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 240)          1920        ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 240)          57840       ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 240)          0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 240)          57840       ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 240)          0           ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 240)          57840       ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 240)          0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 1)            241         ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 175,681\n",
      "Trainable params: 175,681\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4996/5000 [============================>.] - ETA: 0s - loss: 0.0041 - binary_accuracy: 0.9982\n",
      "Epoch 1: val_binary_accuracy improved from -inf to 0.77272, saving model to outputs\\chrisnaa-pipeline\\Trainer\\model\\94\\Format-Serving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Sex_xf, Red_pixel_xf, Green_pixel_xf, Blue_pixel_xf, Hb_xf with unsupported characters which will be renamed to sex_xf, red_pixel_xf, green_pixel_xf, blue_pixel_xf, hb_xf in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: outputs\\chrisnaa-pipeline\\Trainer\\model\\94\\Format-Serving\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: outputs\\chrisnaa-pipeline\\Trainer\\model\\94\\Format-Serving\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 15s 3ms/step - loss: 0.0041 - binary_accuracy: 0.9982 - val_loss: 6.0662 - val_binary_accuracy: 0.7727\n",
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: outputs\\chrisnaa-pipeline\\Trainer\\model\\94\\Format-Serving\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: outputs\\chrisnaa-pipeline\\Trainer\\model\\94\\Format-Serving\\assets\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['----direct_num_workers=0']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000027970648A30> and <keras.engine.input_layer.InputLayer object at 0x0000027970624BE0>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000027970648A30> and <keras.engine.input_layer.InputLayer object at 0x0000027970624BE0>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000002797184C1F0> and <keras.engine.input_layer.InputLayer object at 0x000002797A4B7F10>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000002797184C1F0> and <keras.engine.input_layer.InputLayer object at 0x000002797A4B7F10>).\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000027906949850> and <keras.engine.input_layer.InputLayer object at 0x0000027906A66190>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000027906949850> and <keras.engine.input_layer.InputLayer object at 0x0000027906A66190>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000027906D4A8E0> and <keras.engine.input_layer.InputLayer object at 0x0000027906CF8160>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000027906D4A8E0> and <keras.engine.input_layer.InputLayer object at 0x0000027906CF8160>).\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['----direct_num_workers=0']\n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1741029855   nanos: 516095161 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"c:\\\\Users\\\\febri\\\\miniconda3\\\\envs\\\\mlops-tfx\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:332\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1741029855   nanos: 518099784 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"c:\\\\Users\\\\febri\\\\miniconda3\\\\envs\\\\mlops-tfx\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:352\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1741029859   nanos: 89085578 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000197DB7B7490> and <keras.engine.input_layer.InputLayer object at 0x00000197DB302100>).\" instruction_id: \"bundle_363\" log_location: \"c:\\\\Users\\\\febri\\\\miniconda3\\\\envs\\\\mlops-tfx\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-14\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1741029859   nanos: 415466547 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000197E4144880> and <keras.engine.input_layer.InputLayer object at 0x00000197DB3020A0>).\" instruction_id: \"bundle_363\" log_location: \"c:\\\\Users\\\\febri\\\\miniconda3\\\\envs\\\\mlops-tfx\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-14\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1741029859   nanos: 762125492 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000197E64CAD00> and <keras.engine.input_layer.InputLayer object at 0x00000197E65FB100>).\" instruction_id: \"bundle_363\" log_location: \"c:\\\\Users\\\\febri\\\\miniconda3\\\\envs\\\\mlops-tfx\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-14\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1741029860   nanos: 244098186 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000197E78A1850> and <keras.engine.input_layer.InputLayer object at 0x00000197E65F5EE0>).\" instruction_id: \"bundle_363\" log_location: \"c:\\\\Users\\\\febri\\\\miniconda3\\\\envs\\\\mlops-tfx\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-14\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1741029860   nanos: 310087203 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_363\" transform_id: \"ReadFromTFRecordToArrow[eval][0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"c:\\\\Users\\\\febri\\\\miniconda3\\\\envs\\\\mlops-tfx\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-14\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1741029860   nanos: 891459465 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000197ECD42CA0> and <keras.engine.input_layer.InputLayer object at 0x00000197EBD50250>).\" instruction_id: \"bundle_369\" log_location: \"c:\\\\Users\\\\febri\\\\miniconda3\\\\envs\\\\mlops-tfx\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-14\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1741029861   nanos: 250932455 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000197EE1B8760> and <keras.engine.input_layer.InputLayer object at 0x00000197EDFB92B0>).\" instruction_id: \"bundle_369\" log_location: \"c:\\\\Users\\\\febri\\\\miniconda3\\\\envs\\\\mlops-tfx\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-14\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1741029861   nanos: 735284805 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000197F04035B0> and <keras.engine.input_layer.InputLayer object at 0x00000197EE08ADF0>).\" instruction_id: \"bundle_369\" log_location: \"c:\\\\Users\\\\febri\\\\miniconda3\\\\envs\\\\mlops-tfx\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-14\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1741029862   nanos: 290620565 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000197F1785430> and <keras.engine.input_layer.InputLayer object at 0x00000197F03F70D0>).\" instruction_id: \"bundle_369\" log_location: \"c:\\\\Users\\\\febri\\\\miniconda3\\\\envs\\\\mlops-tfx\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-14\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1741029863   nanos: 187728404 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000197F2B17AF0> and <keras.engine.input_layer.InputLayer object at 0x00000197F2C2EC70>).\" instruction_id: \"bundle_372\" log_location: \"c:\\\\Users\\\\febri\\\\miniconda3\\\\envs\\\\mlops-tfx\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-14\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1741029863   nanos: 702720403 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000197F4FAF7C0> and <keras.engine.input_layer.InputLayer object at 0x00000197F2AF9CD0>).\" instruction_id: \"bundle_372\" log_location: \"c:\\\\Users\\\\febri\\\\miniconda3\\\\envs\\\\mlops-tfx\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-14\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1741029864   nanos: 446922540 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000197F7268E80> and <keras.engine.input_layer.InputLayer object at 0x00000197F7350640>).\" instruction_id: \"bundle_375\" log_location: \"c:\\\\Users\\\\febri\\\\miniconda3\\\\envs\\\\mlops-tfx\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-14\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1741029864   nanos: 972922086 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000197F870DB20> and <keras.engine.input_layer.InputLayer object at 0x00000197F8616D30>).\" instruction_id: \"bundle_375\" log_location: \"c:\\\\Users\\\\febri\\\\miniconda3\\\\envs\\\\mlops-tfx\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-14\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1741029865   nanos: 509237766 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000197F9BA3670> and <keras.engine.input_layer.InputLayer object at 0x00000197F86EA550>).\" instruction_id: \"bundle_375\" log_location: \"c:\\\\Users\\\\febri\\\\miniconda3\\\\envs\\\\mlops-tfx\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-14\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1741029866   nanos: 104588985 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000197FC0261C0> and <keras.engine.input_layer.InputLayer object at 0x00000197F9B9A7F0>).\" instruction_id: \"bundle_375\" log_location: \"c:\\\\Users\\\\febri\\\\miniconda3\\\\envs\\\\mlops-tfx\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-14\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\febri\\miniconda3\\envs\\mlops-tfx\\lib\\site-packages\\tensorflow_model_analysis\\writers\\metrics_plots_and_validations_writer.py:110: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\febri\\miniconda3\\envs\\mlops-tfx\\lib\\site-packages\\tensorflow_model_analysis\\writers\\metrics_plots_and_validations_writer.py:110: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n"
     ]
    }
   ],
   "source": [
    "# Initialize components\n",
    "components = init_components(\n",
    "    args={\n",
    "        \"data_dir\": DATA_ROOT,\n",
    "        \"transform_module\": TRANSFORM_MODULE_FILE,\n",
    "        \"tuner_module\": TUNER_MODULE_FILE,\n",
    "        \"trainer_module\": TRAINER_MODULE_FILE,\n",
    "        \"train_steps\": 5000,\n",
    "        \"eval_steps\": 1000,\n",
    "        \"serving_model_dir\": serving_model_dir\n",
    "    }\n",
    ")\n",
    "\n",
    "# Initialize and run pipeline\n",
    "pipeline = init_local_pipeline(components, pipeline_root)\n",
    "BeamDagRunner().run(pipeline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-tfx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
